{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Required Packages\n",
    "\n",
    "The following packages are required for the python event study code to run:\n",
    "\n",
    "* ipython\n",
    "* pandas (verified at 1.3.1)\n",
    "* statsmodels (verified at 0.12.2)\n",
    "* tabulate (verified at 0.8.9)\n",
    "* wrds (verified at 3.0.10)\n",
    "\n",
    "More recent versions of these packages may work as well, but have not been tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requuired packages\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from datetime import datetime, date\n",
    "from io import StringIO as StringIO_StringIO\n",
    "from json import (\n",
    "    dumps as json_dumps,\n",
    "    dump as json_dump,\n",
    "    load as json_load,\n",
    "    JSONEncoder as json_JSONEncoder,\n",
    ")\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from pandas import (\n",
    "    DataFrame as pd_DataFrame,\n",
    "    ExcelWriter as pd_ExcelWriter,\n",
    ")\n",
    "from numpy import (\n",
    "    abs as np_abs,\n",
    "    nan as np_nan,\n",
    "    mean as np_mean,\n",
    "    std as np_std,\n",
    "    sqrt as np_sqrt,\n",
    "    ndarray as np_ndarray,\n",
    ")\n",
    "\n",
    "from statsmodels.api import (\n",
    "    OLS as sm_OLS,\n",
    "    add_constant as sm_add_constant\n",
    ")\n",
    "from tabulate import tabulate\n",
    "\n",
    "import wrds\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will allows for converting objects other\n",
    "class EncoderJson(json_JSONEncoder):\n",
    "    \"\"\"\n",
    "    Class used to encodes to JSON data format\n",
    "    \"\"\"\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np_ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, datetime):\n",
    "            return obj.__str__()\n",
    "        elif isinstance(obj, date):\n",
    "            return obj.__str__()\n",
    "\n",
    "        return json_JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "#  This is the primary class for the event study and contains all the methods for running it #\n",
    "##############################################################################################\n",
    "\n",
    "class EventStudy(object):\n",
    "    \"\"\"\n",
    "    Main class that runs the event study.\n",
    "    \"\"\"\n",
    "\n",
    "    ###################################################\n",
    "    #  STEP 0 - AUTHENTICATE AND CONNECT TO POSTGRES  #\n",
    "    ###################################################\n",
    "\n",
    "    # parameters when the class is initialized.\n",
    "    # pass an explicit output path for result file\n",
    "    def __init__(self, output_path=''):\n",
    "        if len(output_path) <= 0:\n",
    "            self.output_path = os.path.expanduser('~')\n",
    "        else:\n",
    "            self.output_path = output_path\n",
    "\n",
    "        # Add a flag to indicate whether a message about data issues needs to be printed to the console\n",
    "        self.has_data_issues = False\n",
    "\n",
    "        # Add logging to capture potential data issues\n",
    "        lfpath = os.path.join(self.output_path, \"EventStudy.log\")\n",
    "        logging.basicConfig(filename=lfpath, filemode='w', level=logging.DEBUG)\n",
    "\n",
    "    # Connect to the Postgres database\n",
    "    # Code assumes pgpass file has been created\n",
    "    def connect(self):\n",
    "        \"\"\"\n",
    "        Connect to the Postgres via WRDS.\n",
    "        \"\"\"\n",
    "        self.wrdsconn = wrds.Connection()\n",
    "        self.conn = self.wrdsconn.connect()\n",
    "        return self.wrdsconn\n",
    "\n",
    "    # This is the method that gets called to run the event study. The \"heavy lifting\" happens here.\n",
    "    def eventstudy(self, data=None, model='m', estwin=100, gap=50, evtwins=-10, evtwine=10, minval=70, output='df'):\n",
    "        \"\"\"\n",
    "            Paramaters passed to the event study method.\n",
    "\n",
    "            data        =   event data (event date & permno combinations)\n",
    "            model       =   madj (market-adjusted model)\n",
    "                            m (market model)\n",
    "                            ff (fama french)\n",
    "                            ffm (fama french with momentum factor)\n",
    "            estwin      =   estimation window\n",
    "            gap         =   gap between estimation window and event window\n",
    "            evtwins =   days preceding event date to begin event window\n",
    "            evtwine =   days after event date to close the event window\n",
    "            minval      =   minimum number of non-missing return observations (per event) to be regressed on\n",
    "            output      =   output format of the event study results\n",
    "                            xls (output an excel file to output path)\n",
    "                            csv (output a csv file to output path)\n",
    "                            json (output a json file to output path)\n",
    "                            df (returns a dictionary of pandas dataframes)\n",
    "                            print (outputs results to the console - not available via qsub)\n",
    "        \"\"\"\n",
    "\n",
    "        ####################################################################################\n",
    "        #  STEP 1 - SET ESTIMATION, EVENT, AND GAP WINDOWS AND GRAB DATA FROM EVENTS FILE  #\n",
    "        ####################################################################################\n",
    "\n",
    "        estwins = (estwin + gap + np_abs(evtwins))  # Estimation window start\n",
    "        estwine = (gap + np_abs(evtwins) + 1)       # Estimation window end\n",
    "        evtwinx = (estwins + 1)                     # evt time value (0=event date, -10=window start, 10=window end)\n",
    "        evtwins = np_abs(evtwins)                   # convert the negative to positive as we will use lag function)\n",
    "        evtrang = (evtwins + evtwine + 1)           # total event window days (lag + lead + the day itself)\n",
    "\n",
    "        \"\"\"\n",
    "            With the event date as a fixed point, calculate the number of days needed to pass\n",
    "            to sql lag and lead functions to identify estimation window, gap, and event window.\n",
    "\n",
    "            evtwins:    event date minus number of preceding days\n",
    "                        (\"event date\" - \"number of days before event to start [evtwins parameter]\")\n",
    "\n",
    "            evtwine:    event date plus number of following days\n",
    "                        (\"event date\" + \"number of days after event to end [evtwine parameter]\")\n",
    "\n",
    "            gap:    number of days between the end of the \"estimation window\"\n",
    "                    and the beginning of the \"event window\"\n",
    "\n",
    "            estwins:     start date of the estimation window\n",
    "                        (\"event date\" - \"number of days before event to start [evtwins parameter]\"\n",
    "                                      - \"number of days in gap [gap parameter]\"\n",
    "                                      - \"number of days in estimation window [estwin parameter]\")\n",
    "\n",
    "            evtrang:    entire time range of the event study even from estimate start, through gap,\n",
    "                        until event window end\n",
    "                        (evtwins + evtwine + 1)\n",
    "        \"\"\"\n",
    "\n",
    "        # default the event data in case it was not passed, otherwise read what was passed\n",
    "        evtdata = [{\"edate\": \"05/29/2012\", \"permno\": \"10002\"}]\n",
    "        if data is not None:\n",
    "            evtdata = json_dumps(data)\n",
    "\n",
    "        # init values wrapped up to be passed to sql statement\n",
    "        params = {'estwins': estwins, 'estwine': estwine, 'evtwins': evtwins, 'evtwine': evtwine, 'evtwinx': evtwinx, 'evtdata': evtdata}\n",
    "        #print(params)\n",
    "\n",
    "        #############################################\n",
    "        #  STEP 2 - GET RETURNS DATA FROM POSTGRES  #\n",
    "        #############################################\n",
    "\n",
    "        # Create a database connection\n",
    "        wconn = self.connect()\n",
    "\n",
    "        ##############################################################################\n",
    "        #  Get the initial data from the database and put it in a pandas dataframe   #\n",
    "        ##############################################################################\n",
    "\n",
    "        # create a pandas dataframe that will hold data\n",
    "        df = wconn.raw_sql(\"\"\"\n",
    "        SELECT\n",
    "                a.*,\n",
    "                x.*,\n",
    "                c.date as rdate,\n",
    "                c.ret as ret1,\n",
    "                (f.mktrf+f.rf) as mkt,\n",
    "                f.mktrf,\n",
    "                f.rf,\n",
    "                f.smb,\n",
    "                f.hml,\n",
    "                f.umd,\n",
    "                (1+c.ret)*(coalesce(d.dlret,0.00)+1)-1-(f.mktrf+f.rf) as exret,\n",
    "                (1+c.ret)*(coalesce(d.dlret,0.00)+1)-1 as ret,\n",
    "                case when c.date between a.estwin1 and a.estwin2 then 1 else 0 end as isest,\n",
    "                case when c.date between a.evtwin1 and a.evtwin2 then 1 else 0 end as isevt,\n",
    "                case\n",
    "                  when c.date between a.evtwin1 and a.evtwin2 then (rank() OVER (PARTITION BY x.evtid ORDER BY c.date)-%(evtwinx)s)\n",
    "                  else (rank() OVER (PARTITION BY x.evtid ORDER BY c.date))\n",
    "                end as evttime,\n",
    "                case\n",
    "                  when c.date = a.date then 1\n",
    "                  else 0\n",
    "                end as evtflag\n",
    "        FROM\n",
    "          (\n",
    "            SELECT\n",
    "              date,\n",
    "              lag(date, %(estwins)s ) over (order by date) as estwin1,\n",
    "              lag(date, %(estwine)s )  over (order by date) as estwin2,\n",
    "              lag(date, %(evtwins)s )  over (order by date) as evtwin1,\n",
    "              lead(date, %(evtwine)s )  over (order by date) as evtwin2\n",
    "            FROM crsp_a_stock.dsi\n",
    "          ) as a\n",
    "        JOIN\n",
    "        (select\n",
    "                to_char(x.edate, 'ddMONYYYY') || trim(to_char(x.permno,'999999999')) as evtid,\n",
    "                x.permno,\n",
    "                x.edate\n",
    "        from\n",
    "        json_to_recordset('%(evtdata)s') as x(edate date, permno int)\n",
    "        ) as x\n",
    "          ON a.date=x.edate\n",
    "        JOIN crsp_a_stock.dsf c\n",
    "            ON x.permno=c.permno\n",
    "            AND c.date BETWEEN a.estwin1 and a.evtwin2\n",
    "        JOIN ff_all.factors_daily f\n",
    "            ON c.date=f.date\n",
    "        LEFT JOIN crsp_a_stock.dsedelist d\n",
    "            ON x.permno=d.permno\n",
    "            AND c.date=d.dlstdt\n",
    "        WHERE f.mktrf is not null\n",
    "        AND c.ret is not null\n",
    "        ORDER BY x.evtid, x.permno, a.date, c.date\n",
    "        \"\"\" % params)\n",
    "\n",
    "        # Columns coming from the database query\n",
    "        df.columns = ['date', 'estwin1', 'estwin2', 'evtwin1', 'evtwin2',\n",
    "                      'evtid', 'permno', 'edate', 'rdate', 'ret1', 'mkt',\n",
    "                      'mktrf', 'rf', 'smb', 'hml', 'umd', 'exret', 'ret',\n",
    "                      'isest', 'isevt', 'evttime', 'evtflag']\n",
    "\n",
    "        # Additional columns that will hold computed values (post-query)\n",
    "        addcols = ['RMSE', 'INTERCEPT', 'var_estp', 'expret', 'abret',\n",
    "                   'alpha', '_nobs', '_p_', '_edf_', 'rsq', 'cret',\n",
    "                   'cexpret', 'car', 'scar', 'sar', 'pat_scale', 'bhar',\n",
    "                   'lastevtwin', 'cret_edate', 'scar_edate', 'car_edate',\n",
    "                   'bhar_edate', 'pat_scale_edate', 'xyz']\n",
    "\n",
    "        # Add them to the dataframe\n",
    "        for c in addcols:\n",
    "            if c == 'lastevtwin':\n",
    "                df[c] = 0\n",
    "            else:\n",
    "                df[c] = np_nan\n",
    "\n",
    "\n",
    "        ###################################################################################\n",
    "        #  STEP 3 - FOR EACH EVENT, CALCULATE ABNORMAL RETURN BASED ON CHOSEN RISK MODEL  #\n",
    "        ###################################################################################\n",
    "\n",
    "        # Loop on every category\n",
    "        for evt in data:\n",
    "            permno = evt['permno']\n",
    "            xdate = evt['edate']\n",
    "            edate = datetime.strptime(xdate, \"%m/%d/%Y\").date()\n",
    "\n",
    "            ths_mask = (df['permno'] == permno) & (df['edate'] == edate)\n",
    "            est_mask = (df['permno'] == permno) & (df['edate'] == edate) & (df['isest'] == 1)\n",
    "            evt_mask = (df['permno'] == permno) & (df['edate'] == edate) & (df['isevt'] == 1)\n",
    "            flg_mask = (df['permno'] == permno) & (df['edate'] == edate) & (df['evtflag'] == 1)\n",
    "            err_mask1 = (df['permno'] == permno) & (df['edate'] == edate) & (df['isevt'] == 1) & (df['evttime'] < -1*evtwins)\n",
    "            err_mask2 = (df['permno'] == permno) & (df['edate'] == edate) & (df['isevt'] == 1) & (df['evttime'] > evtwine)\n",
    "\n",
    "            #######################################################\n",
    "            #  Check to see it meets the min obs for est window   #\n",
    "            #######################################################\n",
    "            # number of observations in the estimation window\n",
    "            _nobs = df[\"ret\"][est_mask].count()\n",
    "            # number of actual event date flags - should be 1; if 0 then no data for event\n",
    "            _flgs = df[\"ret\"][flg_mask].count()\n",
    "            # number of observations in the event window; if less than expected we toss?\n",
    "            _wins = df[\"ret\"][evt_mask].count()\n",
    "\n",
    "            # Create a boolean to determine if we need to fix \"evttime\" values because of some underlying data issue\n",
    "            _needs_fix = False\n",
    "            if df[\"evttime\"][err_mask1].count() > 0 or df[\"evttime\"][err_mask2].count() > 0:\n",
    "                _needs_fix = True\n",
    "\n",
    "            ### FIX FOR EVTWIN EVTTIME ###\n",
    "            ### get the row index of where the event flag = 1; we will use this to offset the evttime to fix\n",
    "            if _needs_fix:\n",
    "                evtrow = df[flg_mask]\n",
    "                evtcnt = df[flg_mask][\"evttime\"].count()\n",
    "                if evtcnt > 0:\n",
    "                    evtidx = list(evtrow.index)[0]\n",
    "\n",
    "                    def fixEvtWinTime(row):\n",
    "                        return int(row.name.__int__())-evtidx\n",
    "\n",
    "                    df.loc[evt_mask, \"evttime\"] = df.loc[evt_mask].apply(fixEvtWinTime,axis=1)\n",
    "\n",
    "            # Only carry out the analysis if the number of obsevations meets the minimum threshold\n",
    "            if (_nobs >= minval) and (_flgs > 0) and (_wins == evtrang):\n",
    "\n",
    "                #######################################################\n",
    "                #  Regression based on model choices=''               #\n",
    "                #######################################################\n",
    "\n",
    "                # Market-Adjusted Model\n",
    "                if model == 'madj':\n",
    "                    # Set y to the estimation window records\n",
    "                    y = df[\"exret\"][est_mask]\n",
    "\n",
    "                    # Calculate mean and standard deviation of returns for the estimation period\n",
    "                    mean = np_mean(y)\n",
    "                    stdv = np_std(y, ddof=1)\n",
    "\n",
    "                    # Update the columns in the original dataframe (reusing the names from SAS code to help with continuity)\n",
    "                    df.loc[evt_mask, 'INTERCEPT'] = mean\n",
    "                    df.loc[evt_mask, 'RMSE'] = stdv\n",
    "                    df.loc[evt_mask, '_nobs'] = len(y)\n",
    "                    df.loc[evt_mask, 'var_estp'] = stdv ** 2\n",
    "                    df.loc[evt_mask, 'alpha'] = mean\n",
    "                    df.loc[evt_mask, 'rsq'] = 0\n",
    "                    df.loc[evt_mask, '_p_'] = 1\n",
    "                    df.loc[evt_mask, '_edf_'] = (len(y) - 1)\n",
    "                    df.loc[evt_mask, 'expret'] = df.loc[evt_mask, 'mkt']\n",
    "                    df.loc[evt_mask, 'abret'] = df.loc[evt_mask, 'exret']\n",
    "                    df_est = df[est_mask]\n",
    "                    _nobs = len(df_est[df_est.ret.notnull()])\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cret(row):\n",
    "                        tmp = ((row['ret'] * nloc['const']) + (row['ret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cret'] = df[evt_mask].apply(f_cret, axis=1)\n",
    "                    df.loc[evt_mask, 'cret_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cexpret(row):\n",
    "                        tmp = ((row['expret'] * nloc['const']) + (row['expret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cexpret'] = df[evt_mask].apply(f_cexpret, axis=1)\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_car(row):\n",
    "                        tmp = (row['abret'] + nloc['const'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'car'] = df[evt_mask].apply(f_car, axis=1)\n",
    "                    df.loc[evt_mask, 'car_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_sar(row):\n",
    "                        tmp = (row['abret'] / np_sqrt(row['var_estp']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'sar'] = df[evt_mask].apply(f_sar, axis=1)\n",
    "                    df.loc[evt_mask, 'sar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0, 'evtrang': evtrang}\n",
    "\n",
    "                    def f_scar(row):\n",
    "                        tmp = (row['car'] / np_sqrt((evtrang * row['var_estp'])))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'scar'] = df[evt_mask].apply(f_scar, axis=1)\n",
    "                    df.loc[evt_mask, 'scar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_bhar(row):\n",
    "                        tmp = (row['cret'] - row['cexpret'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'bhar'] = df[evt_mask].apply(f_bhar, axis=1)\n",
    "                    df.loc[evt_mask, 'bhar_edate'] = nloc['const']\n",
    "\n",
    "                    df.loc[evt_mask, 'pat_scale'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "                    df.loc[evt_mask, 'pat_scale_edate'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "\n",
    "                # Market Model\n",
    "                elif model == 'm':\n",
    "                    # Set y to the estimation window records\n",
    "                    X = df[\"mktrf\"][est_mask]\n",
    "                    y = df[\"ret\"][est_mask]\n",
    "\n",
    "                    # Fit an OLS model with intercept on mktrf\n",
    "                    X = sm_add_constant(X)\n",
    "                    est = sm_OLS(y, X).fit()\n",
    "\n",
    "                    # Set the variables from the output\n",
    "                    df_est = df[(df['permno'] == permno) & (df['edate'] == edate) & (df['isest'] == 1)]\n",
    "                    _nobs = len(df_est[df_est.ret.notnull()])   # not null observations\n",
    "\n",
    "                    # aggregate variables\n",
    "                    # cret_edate = np_nan\n",
    "                    # scar_edate = np_nan\n",
    "                    # car_edate = np_nan\n",
    "                    # bhar_edate = np_nan\n",
    "                    # pat_scale_edate = np_nan\n",
    "                    alpha = est.params.__getitem__('const')\n",
    "                    beta1 = est.params.__getitem__('mktrf')\n",
    "\n",
    "                    df.loc[evt_mask, 'INTERCEPT'] = alpha\n",
    "                    df.loc[evt_mask, 'alpha'] = alpha\n",
    "                    df.loc[evt_mask, 'RMSE'] = np_sqrt(est.mse_resid)\n",
    "                    df.loc[evt_mask, '_nobs'] = _nobs\n",
    "                    df.loc[evt_mask, 'var_estp'] = est.mse_resid\n",
    "                    df.loc[evt_mask, 'rsq'] = est.rsquared\n",
    "                    df.loc[evt_mask, '_p_'] = 2\n",
    "                    df.loc[evt_mask, '_edf_'] = (len(y) - 2)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'const': 0}\n",
    "\n",
    "                    def f_expret(row):\n",
    "                        return (nloc['alpha'] + (nloc['beta1'] * row['mktrf']))\n",
    "                    df.loc[evt_mask, 'expret'] = df[evt_mask].apply(f_expret, axis=1)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'const': 0}\n",
    "\n",
    "                    def f_abret(row):\n",
    "                        return (row['ret'] - (nloc['alpha'] + (nloc['beta1'] * row['mktrf'])))\n",
    "                    df.loc[evt_mask, 'abret'] = df[evt_mask].apply(f_abret, axis=1)\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cret(row):\n",
    "                        tmp = ((row['ret'] * nloc['const']) + (row['ret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cret'] = df[evt_mask].apply(f_cret, axis=1)\n",
    "                    df.loc[evt_mask, 'cret_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cexpret(row):\n",
    "                        tmp = ((row['expret'] * nloc['const']) + (row['expret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cexpret'] = df[evt_mask].apply(f_cexpret, axis=1)\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_car(row):\n",
    "                        # nonlocal const\n",
    "                        tmp = (row['abret'] + nloc['const'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'car'] = df[evt_mask].apply(f_car, axis=1)\n",
    "                    df.loc[evt_mask, 'car_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_sar(row):\n",
    "                        tmp = (row['abret'] / np_sqrt(row['var_estp']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'sar'] = df[evt_mask].apply(f_sar, axis=1)\n",
    "                    df.loc[evt_mask, 'sar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0, 'evtrang': evtrang}\n",
    "\n",
    "                    def f_scar(row):\n",
    "                        tmp = (row['car'] / np_sqrt((evtrang * row['var_estp'])))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'scar'] = df[evt_mask].apply(f_scar, axis=1)\n",
    "                    df.loc[evt_mask, 'scar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_bhar(row):\n",
    "                        tmp = (row['cret'] - row['cexpret'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'bhar'] = df[evt_mask].apply(f_bhar, axis=1)\n",
    "                    df.loc[evt_mask, 'bhar_edate'] = nloc['const']\n",
    "\n",
    "                    df.loc[evt_mask, 'pat_scale'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "                    df.loc[evt_mask, 'pat_scale_edate'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "\n",
    "                # Fama-French Three Factor Model\n",
    "                elif model == 'ff':\n",
    "                    # Set y to the estimation window records\n",
    "                    df_est = df[(df['permno'] == permno) & (df['edate'] == edate) & (df['isest'] == 1)]\n",
    "                    X = df_est[['smb', 'hml', 'mktrf']]\n",
    "                    y = df_est['ret']\n",
    "\n",
    "                    # Fit an OLS model with intercept on mktrf, smb, hml\n",
    "                    X = sm_add_constant(X)\n",
    "                    est = sm_OLS(y, X).fit()\n",
    "                    # est = smf.ols(formula='ret ~ smb + hml + mktrf', data=df_est).fit()\n",
    "\n",
    "                    alpha = est.params.__getitem__('const')\n",
    "                    beta1 = est.params.__getitem__('mktrf')\n",
    "                    beta2 = est.params.__getitem__('smb')\n",
    "                    beta3 = est.params.__getitem__('hml')\n",
    "\n",
    "                    df.loc[evt_mask, 'INTERCEPT'] = alpha\n",
    "                    df.loc[evt_mask, 'alpha'] = alpha\n",
    "                    df.loc[evt_mask, 'RMSE'] = np_sqrt(est.mse_resid)\n",
    "                    df.loc[evt_mask, '_nobs'] = _nobs\n",
    "                    df.loc[evt_mask, 'var_estp'] = est.mse_resid\n",
    "                    df.loc[evt_mask, 'rsq'] = est.rsquared\n",
    "                    df.loc[evt_mask, '_p_'] = 2\n",
    "                    df.loc[evt_mask, '_edf_'] = (len(y) - 2)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'beta2': beta2, 'beta3': beta3, 'const': 0}\n",
    "\n",
    "                    def f_expret(row):\n",
    "                        return ((nloc['alpha'] + (nloc['beta1'] * row['mktrf']) + (nloc['beta2'] * row['smb']) + (nloc['beta3'] * row['hml'])))\n",
    "                    df.loc[evt_mask, 'expret'] = df[evt_mask].apply(f_expret, axis=1)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'beta2': beta2, 'beta3': beta3, 'const': 0}\n",
    "\n",
    "                    def f_abret(row):\n",
    "                        return (row['ret'] - ((nloc['alpha'] + (nloc['beta1'] * row['mktrf']) + (nloc['beta2'] * row['smb']) + (nloc['beta3'] * row['hml']))))\n",
    "                    df.loc[evt_mask, 'abret'] = df[evt_mask].apply(f_abret, axis=1)\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cret(row):\n",
    "                        tmp = ((row['ret'] * nloc['const']) + (row['ret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cret'] = df[evt_mask].apply(f_cret, axis=1)\n",
    "                    df.loc[evt_mask, 'cret_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cexpret(row):\n",
    "                        tmp = ((row['expret'] * nloc['const']) + (row['expret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cexpret'] = df[evt_mask].apply(f_cexpret, axis=1)\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_car(row):\n",
    "                        tmp = (row['abret'] + nloc['const'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'car'] = df[evt_mask].apply(f_car, axis=1)\n",
    "                    df.loc[evt_mask, 'car_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_sar(row):\n",
    "                        tmp = (row['abret'] / np_sqrt(row['var_estp']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'sar'] = df[evt_mask].apply(f_sar, axis=1)\n",
    "                    df.loc[evt_mask, 'sar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0, 'evtrang': evtrang}\n",
    "\n",
    "                    def f_scar(row):\n",
    "                        tmp = (row['car'] / np_sqrt((evtrang * row['var_estp'])))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'scar'] = df[evt_mask].apply(f_scar, axis=1)\n",
    "                    df.loc[evt_mask, 'scar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_bhar(row):\n",
    "                        tmp = (row['cret'] - row['cexpret'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'bhar'] = df[evt_mask].apply(f_bhar, axis=1)\n",
    "                    df.loc[evt_mask, 'bhar_edate'] = nloc['const']\n",
    "\n",
    "                    df.loc[evt_mask, 'pat_scale'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "                    df.loc[evt_mask, 'pat_scale_edate'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "\n",
    "                # Fama-French Plus Momentum\n",
    "                elif model == 'ffm':\n",
    "                    # Set y to the estimation window records\n",
    "                    df_est = df[(df['permno'] == permno) & (df['edate'] == edate) & (df['isest'] == 1)]\n",
    "\n",
    "                    X = df_est[['mktrf', 'smb', 'hml', 'umd']]  # indicator variables\n",
    "                    y = df_est['ret']                           # response variables\n",
    "\n",
    "                    # Fit an OLS (ordinary least squares) model with intercept on mktrf, smb, hml, and umd\n",
    "                    X = sm_add_constant(X)\n",
    "                    est = sm_OLS(y, X).fit()\n",
    "\n",
    "                    alpha = est.params.__getitem__('const')\n",
    "                    beta1 = est.params.__getitem__('mktrf')\n",
    "                    beta2 = est.params.__getitem__('smb')\n",
    "                    beta3 = est.params.__getitem__('hml')\n",
    "                    beta4 = est.params.__getitem__('umd')\n",
    "\n",
    "                    df.loc[evt_mask, 'INTERCEPT'] = alpha\n",
    "                    df.loc[evt_mask, 'alpha'] = alpha\n",
    "                    df.loc[evt_mask, 'RMSE'] = np_sqrt(est.mse_resid)\n",
    "                    df.loc[evt_mask, '_nobs'] = _nobs\n",
    "                    df.loc[evt_mask, 'var_estp'] = est.mse_resid\n",
    "                    df.loc[evt_mask, 'rsq'] = est.rsquared\n",
    "                    df.loc[evt_mask, '_p_'] = 2\n",
    "                    df.loc[evt_mask, '_edf_'] = (len(y) - 2)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'beta2': beta2, 'beta3': beta3, 'beta4': beta4, 'const': 0}\n",
    "\n",
    "                    def f_expret(row):\n",
    "                        return ((nloc['alpha'] + (nloc['beta1'] * row['mktrf']) + (nloc['beta2'] * row['smb']) + (nloc['beta3'] * row['hml']) + (nloc['beta4'] * row['umd'])))\n",
    "                    df.loc[evt_mask, 'expret'] = df[evt_mask].apply(f_expret, axis=1)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'beta2': beta2, 'beta3': beta3, 'beta4': beta4, 'const': 0}\n",
    "\n",
    "                    def f_abret(row):\n",
    "                        return (row['ret'] - ((nloc['alpha'] + (nloc['beta1'] * row['mktrf']) + (nloc['beta2'] * row['smb']) + (nloc['beta3'] * row['hml']) + (nloc['beta4'] * row['umd']))))\n",
    "                    df.loc[evt_mask, 'abret'] = df[evt_mask].apply(f_abret, axis=1)\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cret(row):\n",
    "                        tmp = ((row['ret'] * nloc['const']) + (row['ret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cret'] = df[evt_mask].apply(f_cret, axis=1)\n",
    "                    df.loc[evt_mask, 'cret_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cexpret(row):\n",
    "                        tmp = ((row['expret'] * nloc['const']) + (row['expret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cexpret'] = df[evt_mask].apply(f_cexpret, axis=1)\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_car(row):\n",
    "                        tmp = (row['abret'] + nloc['const'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'car'] = df[evt_mask].apply(f_car, axis=1)\n",
    "                    df.loc[evt_mask, 'car_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_sar(row):\n",
    "                        tmp = (row['abret'] / np_sqrt(row['var_estp']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'sar'] = df[evt_mask].apply(f_sar, axis=1)\n",
    "                    df.loc[evt_mask, 'sar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0, 'evtrang': evtrang}\n",
    "\n",
    "                    def f_scar(row):\n",
    "                        tmp = (row['car'] / np_sqrt((evtrang * row['var_estp'])))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'scar'] = df[evt_mask].apply(f_scar, axis=1)\n",
    "                    df.loc[evt_mask, 'scar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_bhar(row):\n",
    "                        tmp = (row['cret'] - row['cexpret'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'bhar'] = df[evt_mask].apply(f_bhar, axis=1)\n",
    "                    df.loc[evt_mask, 'bhar_edate'] = nloc['const']\n",
    "\n",
    "                    df.loc[evt_mask, 'pat_scale'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "                    df.loc[evt_mask, 'pat_scale_edate'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "                # Something erroneous was passed\n",
    "                else:\n",
    "                    df['isest'][evt_mask] = -2\n",
    "\n",
    "            ### EVENT FAILED DATA CHECKS....\n",
    "            ### Estimation window must have the minimum number of days passed as a parameter (default = 70)\n",
    "            ### There must be one record where evtflag=1 per event coming from the sql ...\n",
    "            ### ... the flag is set to 1 when the event date passed equals a date from crsp dsi and dsf\n",
    "            ### ... if no observation has the flag == 1 then that date must be missing from crsp dsi or dsf\n",
    "            ### The number of observationds/days in the event window must be equal to the number set ...\n",
    "            ### ... e.g. if window starts 10 before event and ends 10 after, there should be 21 obs: 10 + 10 + 1 (the one is the event itself)\n",
    "            else:\n",
    "                # we drop those events from the datafrom \n",
    "                self.has_data_issues = True\n",
    "                df.drop(df.loc[ths_mask].index, inplace=True)\n",
    "                logging.warning(\"\\nFailed data check: \" + str(evt) + \"\\n\"\n",
    "                                \"Estimation Window Obs: \" + str(_nobs) + \"; Min Required: \" + str(minval) + \"\\n\" + \n",
    "                                \"Event Date Flag: \" + str(_flgs) + \"\\n\" + \n",
    "                                \"Event Window Obs: \" + str(_wins) + \"; Expected: \" + str(evtrang) + \"\\n\" + \n",
    "                                \"--------------------\" + \"\\n\")\n",
    "\n",
    "        # If any events had bad data, print to console\n",
    "        if self.has_data_issues:\n",
    "            print(\"NOTE: Some data related issues were encountered. Please consult the log file (\"+os.path.join(self.output_path, 'EventStudy.log')+\").\")\n",
    "\n",
    "        #################################\n",
    "        #  STEP 4 - OUTPUT THE RESULTS  #\n",
    "        #################################\n",
    "        df_sta = df[df['isevt'] == 1]\n",
    "        levt = df_sta['evttime'].unique()\n",
    "\n",
    "        columns = ['evttime',\n",
    "                   'car_m',\n",
    "                   'ret_m',\n",
    "                   'abret_m',\n",
    "                   'abret_t',\n",
    "                   'sar_t',\n",
    "                   'pat_ar',\n",
    "                   'cret_edate_m',\n",
    "                   'car_edate_m',\n",
    "                   'pat_car_edate_m',\n",
    "                   'car_edate_t',\n",
    "                   'scar_edate_t',\n",
    "                   'bhar_edate_m']\n",
    "\n",
    "        idxlist = list(levt)\n",
    "        df_stats = pd_DataFrame(index=idxlist, columns=columns)\n",
    "        df_stats = df_stats.fillna(0.00000000)  # with 0s rather than NaNs\n",
    "\n",
    "        # Event\n",
    "        df_stats['evttime'] = df_sta.groupby(['evttime'])['evttime'].unique()\n",
    "        # Means\n",
    "        df_stats['abret_m'] = df_sta.groupby(['evttime'])['abret'].mean()\n",
    "        df_stats['bhar_edate_m'] = df_sta.groupby(['evttime'])['bhar_edate'].mean()\n",
    "        df_stats['car_edate_m'] = df_sta.groupby(['evttime'])['car_edate'].mean()\n",
    "        df_stats['car_m'] = df_sta.groupby(['evttime'])['car'].mean()\n",
    "        df_stats['cret_edate_m'] = df_sta.groupby(['evttime'])['cret_edate'].mean()\n",
    "        df_stats['pat_scale_m'] = df_sta.groupby(['evttime'])['pat_scale'].mean()\n",
    "        df_stats['pat_car_edate_mean'] = 0\n",
    "        df_stats['ret_m'] = df_sta.groupby(['evttime'])['ret'].mean()\n",
    "        df_stats['sar_m'] = df_sta.groupby(['evttime'])['sar'].mean()\n",
    "        df_stats['scar_edate_m'] = df_sta.groupby(['evttime'])['scar_edate'].mean()\n",
    "        df_stats['scar_m'] = df_sta.groupby(['evttime'])['scar'].mean()\n",
    "        # Standard deviations\n",
    "        df_stats['car_v'] = df_sta.groupby(['evttime'])['car'].std()\n",
    "        df_stats['abret_v'] = df_sta.groupby(['evttime'])['abret'].std()\n",
    "        df_stats['sar_v'] = df_sta.groupby(['evttime'])['sar'].std()\n",
    "        df_stats['pat_scale_v'] = df_sta.groupby(['evttime'])['pat_scale'].std()\n",
    "        df_stats['car_edate_v'] = df_sta.groupby(['evttime'])['car_edate'].std()\n",
    "        df_stats['scar_edate_v'] = df_sta.groupby(['evttime'])['scar_edate'].std()\n",
    "        df_stats['scar_v'] = df_sta.groupby(['evttime'])['scar'].std()\n",
    "        # Counts\n",
    "        df_stats['scar_n'] = df_sta.groupby(['evttime'])['scar'].count()\n",
    "        df_stats['scar_edate_n'] = df_sta.groupby(['evttime'])['scar_edate'].count()\n",
    "        df_stats['sar_n'] = df_sta.groupby(['evttime'])['sar'].count()\n",
    "        df_stats['car_n'] = df_sta.groupby(['evttime'])['car'].count()\n",
    "        df_stats['n'] = df_sta.groupby(['evttime'])['evttime'].count()\n",
    "        # Sums\n",
    "        df_stats['pat_scale_edate_s'] = df_sta.groupby(['evttime'])['pat_scale_edate'].sum()\n",
    "        df_stats['pat_scale_s'] = df_sta.groupby(['evttime'])['pat_scale'].sum()\n",
    "\n",
    "        # T statistics 1\n",
    "        def tstat(row, m, v, n):\n",
    "            return row[m] / (row[v] / np_sqrt(row[n]))\n",
    "\n",
    "        df_stats['abret_t'] = df_stats.apply(tstat, axis=1, args=('abret_m', 'abret_v', 'n'))\n",
    "        df_stats['sar_t'] = df_stats.apply(tstat, axis=1, args=('sar_m', 'sar_v', 'n'))\n",
    "        df_stats['car_edate_t'] = df_stats.apply(tstat, axis=1, args=('car_edate_m', 'car_edate_v', 'n'))\n",
    "        df_stats['scar_edate_t'] = df_stats.apply(tstat, axis=1, args=('scar_edate_m', 'scar_edate_v', 'scar_edate_n'))\n",
    "\n",
    "        # T statistics 2\n",
    "        def tstat2(row, m, s, n):\n",
    "            try:\n",
    "                return row[m] / (np_sqrt(row[s]) / row[n])\n",
    "            except:\n",
    "                return 0\n",
    "\n",
    "        df_stats['pat_car'] = df_stats.apply(tstat2, axis=1, args=('scar_m', 'pat_scale_s', 'scar_n'))\n",
    "        df_stats['pat_car_edate_m'] = df_stats.apply(tstat2, axis=1, args=('scar_edate_m', 'pat_scale_edate_s', 'scar_edate_n'))\n",
    "        df_stats['pat_ar'] = df_stats.apply(tstat2, axis=1, args=('sar_m', 'pat_scale_s', 'sar_n'))\n",
    "\n",
    "        # FILE 2\n",
    "        # EVENT WINDOW\n",
    "        df_evtw = df.loc[(df['isevt'] == 1), ['permno', 'edate', 'rdate', 'evttime', 'ret', 'abret']]\n",
    "        df_evtw.sort_values(['permno', 'evttime'], ascending=[True, True])\n",
    "\n",
    "        # FILE 1\n",
    "        # EVENT DATE\n",
    "        maxv = max(levt)\n",
    "        df_evtd = df.loc[(df['isevt'] == 1) & (df['evttime'] == maxv), ['permno', 'edate', 'cret', 'car', 'bhar']]\n",
    "        df_evtd.sort_values(['permno', 'edate'], ascending=[True, True])\n",
    "\n",
    "        if output == 'df':\n",
    "            retval = {}\n",
    "            retval['event_stats'] = df_stats\n",
    "            retval['event_window'] = df_evtw\n",
    "            retval['event_date'] = df_evtd\n",
    "            return retval\n",
    "        elif output == 'print':\n",
    "            retval = {}\n",
    "            \n",
    "            # This replaces the command line output (commented out below) with jupyter friendly html\n",
    "            tbl1 = tabulate(df_evtd.sort_values(['permno', 'edate'], ascending=[True, True]), headers='keys', tablefmt='html')\n",
    "            display(HTML('<br><br><h5>Event Date</h5>'))\n",
    "            display(HTML(tbl1))\n",
    "            tbl2 = tabulate(df_evtw, headers='keys', tablefmt='html')\n",
    "            display(HTML('<br><h5>Event Window</h5>'))\n",
    "            display(HTML(tbl2))\n",
    "            tbl3 = tabulate(df_stats, headers='keys', tablefmt='html')\n",
    "            display(HTML('<br><h5>Cross-Sectional Statistics</h5>'))\n",
    "            display(HTML(tbl3))\n",
    "            \n",
    "            #print(tabulate(df_evtd.sort_values(['permno', 'edate'], ascending=[True, True]), headers='keys', tablefmt='html'))\n",
    "            #print(tabulate(df_evtw, headers='keys', tablefmt='html'))\n",
    "            #print(tabulate(df_stats, headers='keys', tablefmt='html'))\n",
    "            \n",
    "            return retval\n",
    "        elif output == 'json':\n",
    "            retval = {}\n",
    "            retval['event_stats'] = df_stats.to_dict(orient='split')\n",
    "            retval['event_window'] = df_evtw.to_dict(orient='split')\n",
    "            retval['event_date'] = df_evtd.to_dict(orient='split')\n",
    "            # Write this to a file\n",
    "            with open(os.path.join(self.output_path, 'EventStudy.json'), 'w') as outfile:\n",
    "                json_dump(retval, outfile, cls=EncoderJson)\n",
    "            # Return the output in case they are doing something programmatically\n",
    "            return json_dumps(retval, cls=EncoderJson)\n",
    "        elif output == 'csv':\n",
    "            retval = ''\n",
    "            es = StringIO_StringIO()\n",
    "            df_stats.to_csv(es)\n",
    "            retval += es.getvalue()\n",
    "            ew = StringIO_StringIO()\n",
    "            df_evtw.to_csv(ew)\n",
    "            retval += \"\\r\"\n",
    "            retval += ew.getvalue()\n",
    "            ed = StringIO_StringIO()\n",
    "            df_evtd.to_csv(ed)\n",
    "            retval += ed.getvalue()\n",
    "\n",
    "            # write this to a file\n",
    "            with open(os.path.join(self.output_path, 'EventStudy.csv'), 'w') as outfile:\n",
    "                outfile.write(retval)\n",
    "\n",
    "            # return the output in case they are doing something programmatically\n",
    "            return retval\n",
    "        elif output == 'xls':\n",
    "            retval = {}\n",
    "            xlswriter = pd_ExcelWriter(os.path.join(self.output_path, 'EventStudy.xls'))\n",
    "            df_stats.to_excel(xlswriter, 'Stats')\n",
    "            df_evtw.to_excel(xlswriter, 'Event Window')\n",
    "            df_evtd.to_excel(xlswriter, 'Event Date')\n",
    "            xlswriter.save()\n",
    "            return retval\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#  Instantiate the class and call the function  #\n",
    "#################################################\n",
    "\n",
    "# Use absolute path: /home/[institution]/[username]/ (e.g. /home/wharton/jwharton/)\n",
    "# This is the path where both logging and a results file (depending on output choice) will be written\n",
    "from pathlib import Path\n",
    "eventstudy = EventStudy(output_path=os.path.join(Path.home())) \n",
    "\n",
    "# The syntax commented out below allows the user to read from an event file as opposed to pasting it in the code\n",
    "# from pathlib import Path\n",
    "# with open(os.path.join(Path.home(),'/event_study/sample.json')) as data_file:\n",
    "#     events = json_load(data_file)\n",
    "\n",
    "# A simple list of sample events\n",
    "events = [{\"permno\":10002,\"edate\":\"05/29/2012\"},\n",
    "           {\"permno\":82504,\"edate\":\"05/29/2012\"},\n",
    "           {\"permno\":89350,\"edate\":\"01/04/2010\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "# data        =   event data (event date & permno combinations)\n",
    "# model       =   madj (market-adjusted model)\n",
    "#                 m (market model)\n",
    "#                 ff (fama french)\n",
    "#                 ffm (fama french with momentum factor)\n",
    "# estwin      =   estimation window (Default: 100)\n",
    "# gap         =   gap between estimation window and event window (Default: 50)\n",
    "# evtwins =   days preceding event date to begin event window (Default: -10)\n",
    "# evtwine =   days after event date to close the event window (Default: 10)\n",
    "# minval      =   minimum number of non-missing return observations (per event) to be regressed on (Default: 70)\n",
    "# output      =   output format of the event study results\n",
    "#                 xls (output an excel file to output path)\n",
    "#                 csv (output a csv file to output path)\n",
    "#                 json (output a json file to output path)\n",
    "#                 df (returns a dictionary of pandas dataframes) (Default option)\n",
    "#                 print (outputs results to the console - not available via qsub)\n",
    "\n",
    "# Example with the minimum parameters passed\n",
    "result = eventstudy.eventstudy(data=events, model='madj', output='print')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
