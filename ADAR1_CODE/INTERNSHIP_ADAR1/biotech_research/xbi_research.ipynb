{"cells":[{"cell_type":"markdown","source":["# TASK:\n","Okay, had some time to pull data. I've attached a couple of reports on ARQT just so that you can get an idea of how investors are looking at/evaluting biotechs generally, but the most value that you'll be able to create for us will be on the quantitative side, so that is the best place to focus for you to have the highest impact.\n","\n","So, here's something to give a crack. It'd be really helpful to try to quantify \"what moves the XBI?\" So, I've included returns of XBI and other equity indices, bond yields, fund flows (you can calculate these by using the XBI Market Cap tab and calculating week over week changes in total market cap), and a list of historical M&A events. We would love to get an idea of how we can decompose XBI returns to figure out the most predictive variables.\n","\n","Some examples of valuable output would be things like:\n","\n","If there is an acquisition of more than X billion, XBI will generate outperformance of Y% over the next Z days or weeks\n","XBI is most sensitive to X factor historically (maybe bond yields or microcap returns or frequency of M&A), and Y tends to be a leading indicator of this outperformance\"\n","\"If yields rise more than X% in a Y-month period, future XBI returns underperform by Z%\n","Mega M&A (>$10bn) moves XBI X% more than smaller M&A events and produces more/less predictable XBI performance\n","\n","It would also be helpful to see if M&A events drive positive fund flows. If so, maybe there's a predictable link between M&A -> positive fund flows -> rising XBI price\n","\n","Also, consider using the 10 year or 30 year yields and subtracting the 2 year yield to determine if the yield curve is inverted or not. Maybe XBI returns are different or correlations change if the yield curve is inverted?\n","\n","Other factors that you could generate/use would be the political party that is in control, especially of the FTC. You could quantify each year on some metric of leniency to strictness on pursuing FTC action against pharma acquisitions, and then see if this has a correlation with M&A frequency and XBI returns. For example, I'd classify Lina Khan as being fairly strict. Have there been fewer acquisitions this year than normal? Maybe the # has been the same, but the $ value is lower? What do historical correlations tell us about expected XBI returns in an environment like that?\n","\n","Also, consider looking at XBI performance during historical election years. Is there typically less M&A during the 6-9 months preceding an election, and does this typically result in a weaker XBI?\n","\n","One factor that I'd love to include (but can't figure out yet) is if there have been impactful data readouts for the sector. I have anecdotally noticed that XBI tends to perform well if there has been a high $ value or % move catalyst in SMID cap name recently. Maybe this attracts more investors to XBI, or maybe it causes shorts to cover a little bit? If you can think of some scalable way to identify past big data events, that'd be cool.\n","\n","Let me know if you have any questions. This should be a fairly open project, we want to see how much can we quantify to predict XBI performance. Feel free to add in any additional factors/analyses that you think could be helpful."],"metadata":{"id":"1PlgMNknt242"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import statsmodels.api as sm\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","\n","pd.set_option('display.max_columns', None)\n","\n","\n","xls = pd.ExcelFile('Historical XBI Driver Data.xlsx')\n","\n","# Load XBI data\n","df_xbi = pd.read_excel(xls, sheet_name=\"XBI\", skiprows=6)\n","\n","# Load IBB data\n","df_ibb = pd.read_excel(xls, sheet_name=\"IBB\", skiprows=6)\n","\n","# Load IWM data\n","df_iwm = pd.read_excel(xls, sheet_name=\"IWM\", skiprows=6)\n","\n","# Load IWC data\n","df_iwc = pd.read_excel(xls, sheet_name=\"IWC\", skiprows=6)\n","\n","# Load QQQ data\n","df_qqq = pd.read_excel(xls, sheet_name=\"QQQ\", skiprows=6)\n","\n","# Load XLV data\n","df_xlv = pd.read_excel(xls, sheet_name=\"XLV\", skiprows=6)\n","\n","# Load US2Y data\n","df_us2y = pd.read_excel(xls, sheet_name=\"US2Y\", skiprows=5)\n","\n","# Load US10Y data\n","df_us10y = pd.read_excel(xls, sheet_name=\"US10Y\", skiprows=5)\n","\n","# Load US30Y data\n","df_us30y = pd.read_excel(xls, sheet_name=\"US30Y\", skiprows=5)\n","\n","# Load XBI Market Cap data\n","df_mktcap_xbi = pd.read_excel(xls, sheet_name=\"XBI Market Cap\", skiprows=6)\n","\n","# Load All M&A data\n","df_all_ma = pd.read_excel(xls, sheet_name=\"All M&A (>$500M)\", skiprows=6)\n","\n","# Load Mega M&A data\n","df_mega_ma = pd.read_excel(xls, sheet_name=\"Mega M&A (>$10B)\", skiprows=5)\n","\n","# Load SMID M&A data\n","df_smid_ma = pd.read_excel(xls, sheet_name=\"SMID M&A ($1-10B)\", skiprows=5)\n","\n","df_xbi.rename(columns={\n","    'PX_LAST': 'Price_Last',\n","    'Change': 'Price_Change',\n","    '% Change': 'Price_Percent_Change',\n","    'PX_VOLUME': 'Volume',\n","    'Change.1': 'Volume_Change',\n","    '% Change.1': 'Volume_Percent_Change'\n","}, inplace=True)\n","\n","# Rename columns for clarity\n","df_ibb.rename(columns={\n","    'PX_LAST': 'Price_Last',\n","    'Change': 'Price_Change',\n","    '% Change': 'Price_Percent_Change',\n","    'PX_VOLUME': 'Volume',\n","    'Change.1': 'Volume_Change',\n","    '% Change.1': 'Volume_Percent_Change'\n","}, inplace=True)\n","\n","df_iwm.rename(columns={\n","    'PX_LAST': 'Price_Last',\n","    'Change': 'Price_Change',\n","    '% Change': 'Price_Percent_Change',\n","    'PX_VOLUME': 'Volume',\n","    'Change.1': 'Volume_Change',\n","    '% Change.1': 'Volume_Percent_Change'\n","}, inplace=True)\n","\n","\n","# Assuming the numerical dates in df_ibb are days since 1 January 1970\n","\n","# If needed, convert the date column in df_xbi to datetime for consistency\n","df_xbi['Date'] = pd.to_datetime(df_xbi['Date'])\n","\n","# Convert the numerical dates to datetime\n","df_ibb['Date'] = pd.to_datetime(df_ibb['Date'], origin='1899-12-30', unit='D')\n","df_iwm['Date'] = pd.to_datetime(df_iwm['Date'], origin='1899-12-30', unit='D')\n","df_iwc['Date'] = pd.to_datetime(df_iwc['Date'], origin='1899-12-30', unit='D')\n","df_qqq['Date'] = pd.to_datetime(df_qqq['Date'], origin='1899-12-30', unit='D')\n","df_xlv['Date'] = pd.to_datetime(df_xlv['Date'], origin='1899-12-30', unit='D')\n","df_us2y['Date'] = pd.to_datetime(df_us2y['Date'], origin='1899-12-30', unit='D')\n","df_us10y['Date'] = pd.to_datetime(df_us10y['Date'], origin='1899-12-30', unit='D')\n","df_us30y['Date'] = pd.to_datetime(df_us30y['Date'], origin='1899-12-30', unit='D')\n","df_mktcap_xbi['Date'] = pd.to_datetime(df_mktcap_xbi['Date'], origin='1899-12-30', unit='D')\n","\n","df_all_ma = df_all_ma.loc[:, ~df_all_ma.columns.str.contains('^Unnamed')]\n","df_all_ma.rename(columns={\n","    'Date Announced': 'Date_Announced',\n","    'Deal Value \\n($B)': 'Deal_Value_Billion',\n","    'LTM sales\\n($M)': 'LTM_Sales_Million',\n","    'Peak Sales** \\nEst ($M)': 'Peak_Sales_Est_Million',\n","    'Deal value/ LTM sales': 'Deal_Value_LTM_Sales',\n","    'Deal value/ Peak sales': 'Deal_Value_Peak_Sales',\n","    'Takeout Forward P/E': 'Takeout_Forward_PE',\n","    '90 Day Premium': '90_Day_Premium',\n","    'Cash / Stock*': 'Cash_Stock',\n","    'Termination Fees': 'Termination_Fees',\n","    'Financial Advisor (Target)': 'Financial_Advisor_Target',\n","    'Financial Advisor (Acquirer)': 'Financial_Advisor_Acquirer',\n","    'PR on Target\\'s Website': 'PR_Target_Website'\n","}, inplace=True)\n","\n","\n","# Remove unnecessary columns\n","columns_to_keep_mega = ['Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Deal Value \\n($B)', 'LTM sales\\n($M)', 'Peak Sales** \\nEst ($M)', 'Deal value/ LTM sales', 'Deal value/ Peak sales', 'Takeout Forward P/E', 'Cash / Stock*', 'Termination Fees', 'Financial Advisor (Target)', 'Financial Advisor (Acquirer)', 'Unnamed: 18']\n","df_mega_ma = df_mega_ma[columns_to_keep_mega]\n","\n","# Rename columns\n","df_mega_ma.columns = ['Date', 'Acquirer', 'Target', 'Product', 'Indication', 'Therapeutic_Area', 'Stage', 'Deal_Value_B', 'LTM_Sales_M', 'Peak_Sales_Est_M', 'Deal_Value_LTM_Sales_Ratio', 'Deal_Value_Peak_Sales_Ratio', 'Takeout_Forward_PE', 'Cash_Stock', 'Termination_Fees', 'Financial_Advisor_Target', 'Financial_Advisor_Acquirer', 'Is_Completed']\n","\n","# Remove unnecessary columns\n","columns_to_keep_smid = ['Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Deal Value \\n($B)', 'LTM sales\\n($M)', 'Peak Sales** \\nEst ($M)', 'Deal value/ LTM sales', 'Deal value/ Peak sales', 'Takeout Forward P/E', '90 Day Premium', 'Cash / Stock*', 'Termination Fees', 'Financial Advisor (Target)', 'Financial Advisor (Acquirer)', 'Unnamed: 19']\n","df_smid_ma = df_smid_ma[columns_to_keep_smid]\n","\n","# Rename columns\n","df_smid_ma.columns = ['Date', 'Acquirer', 'Target', 'Product', 'Indication', 'Therapeutic_Area', 'Stage', 'Deal_Value_B', 'LTM_Sales_M', 'Peak_Sales_Est_M', 'Deal_Value_LTM_Sales_Ratio', 'Deal_Value_Peak_Sales_Ratio', 'Takeout_Forward_PE', 'Premium_90_Day', 'Cash_Stock', 'Termination_Fees', 'Financial_Advisor_Target', 'Financial_Advisor_Acquirer', 'Is_Completed']\n","\n","def clean_year_dataset(df):\n","    # 1. Rename columns for clarity\n","    df.columns = ['Date', 'PX_LAST', 'Change', '% Change', 'PX_BID', 'Change_BID', '% Change_BID']\n","\n","    # 2. Convert 'Date' to datetime format\n","    df['Date'] = pd.to_datetime(df['Date'])\n","\n","    # 3. Convert numerical columns to float\n","    numeric_cols = ['PX_LAST', 'Change', '% Change', 'PX_BID', 'Change_BID', '% Change_BID']\n","    #df[numeric_cols] = df[numeric_cols].astype(float)\n","\n","    return df\n","\n","df_us2y = clean_year_dataset(df_us2y)\n","df_us10y = clean_year_dataset(df_us10y)\n","df_us30y = clean_year_dataset(df_us30y)\n","\n","df_all_ma = df_all_ma.dropna(subset=['Date_Announced'])\n","df_mega_ma = df_mega_ma.dropna(subset=['Date'])\n","df_smid_ma = df_smid_ma.dropna(subset=['Date'])\n","\n","# Create a temporary string column\n","df_all_ma['Date_Announced_Str'] = df_all_ma['Date_Announced'].astype(str)\n","# Filter rows that contain '00:00:00'\n","df_all_ma = df_all_ma[df_all_ma['Date_Announced_Str'].str.contains('00:00:00', na=False)]\n","# Drop the temporary column\n","df_all_ma = df_all_ma.drop('Date_Announced_Str', axis=1)\n","\n","# Create a temporary string column\n","df_smid_ma['Date_Announced_Str'] = df_smid_ma['Date'].astype(str)\n","# Filter rows that contain '00:00:00'\n","df_smid_ma = df_smid_ma[df_smid_ma['Date_Announced_Str'].str.contains('00:00:00', na=False)]\n","# Drop the temporary column\n","df_smid_ma = df_smid_ma.drop('Date_Announced_Str', axis=1)\n","\n","# Create a temporary string column\n","df_mega_ma['Date_Announced_Str'] = df_mega_ma['Date'].astype(str)\n","# Filter rows that contain '00:00:00'\n","df_mega_ma = df_mega_ma[df_mega_ma['Date_Announced_Str'].str.contains('00:00:00', na=False)]\n","# Drop the temporary column\n","df_mega_ma = df_mega_ma.drop('Date_Announced_Str', axis=1)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qa-opdXqm7L_","executionInfo":{"status":"ok","timestamp":1724903882862,"user_tz":420,"elapsed":5828,"user":{"displayName":"Mukeshwaran Baskaran","userId":"01625547661572205085"}},"outputId":"10bd001f-8c63-42ed-fb68-aee7a43db878"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-46bbeafc61d4>:100: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_all_ma.rename(columns={\n"]}]},{"cell_type":"code","source":["# Function to calculate fund flows\n","def calculate_fund_flows(df):\n","    df['Market_Cap_Change'] = df['CUR_MKT_CAP'].pct_change()\n","    return df\n","\n","# Calculate fund flows for XBI\n","df_mktcap_xbi = calculate_fund_flows(df_mktcap_xbi)\n","\n","# Function to calculate M&A frequency\n","def calculate_ma_frequency(df):\n","    df['M&A_Frequency'] = df['Deal_Value_B'].rolling(window=12).mean()\n","    return df\n","\n","# Calculate M&A frequency for Mega M&A\n","df_mega_ma = calculate_ma_frequency(df_mega_ma)\n","\n","# Function to calculate yield curve inversion\n","def calculate_yield_curve_inversion(df):\n","    df['Yield_Curve_Inversion'] = df['US10Y'] - df['US2Y']\n","    return df\n","\n","# Calculate yield curve inversion for US10Y and US2Y\n","df_us10y = calculate_yield_curve_inversion(df_us10y)\n","df_us2y = calculate_yield_curve_inversion(df_us2y)\n","\n","# Function to calculate political party control\n","def calculate_political_party_control(df):\n","    df['Political_Party_Control'] = np.where(df['Year'] % 4 == 0, 'Democratic', np.where(df['Year'] % 4 == 1, 'Republican', 'Other'))\n","    return df\n","\n","# Calculate political party control for Mega M&A\n","df_mega_ma = calculate_political_party_control(df_mega_ma)\n","\n","# Function to calculate data readouts\n","def calculate_data_readouts(df):\n","    df['Data_Readouts'] = np.where(df['Year'] % 4 == 0, 1, 0)\n","    return df\n","\n","# Calculate data readouts for Mega M&A\n","df_mega_ma = calculate_data_readouts(df_mega_ma)\n","\n","# Function to calculate M&A size\n","def calculate_ma_size(df):\n","    df['M&A_Size'] = np.where(df['Deal_Value_B'] > 10, 'Large', 'Small')\n","    return df\n","\n","# Calculate M&A size for Mega M&A\n","df_mega_ma = calculate_ma_size(df_mega_ma)\n","\n","# Function to calculate XBI returns\n","def calculate_xbi_returns(df):\n","    df['XBI_Returns'] = df['Price_Last'].pct_change()\n","    return df\n","\n","# Calculate XBI returns for XBI\n","df_xbi = calculate_xbi_returns(df_xbi)\n","\n","# Function to calculate correlations\n","def calculate_correlations(df):\n","    df['Correlations'] = df['XBI_Returns'].corr(df['M&A_Frequency'])\n","    return df\n","\n","# Calculate correlations for Mega M&A\n","df_mega_ma = calculate_correlations(df_mega_ma)\n","\n","# Function to train linear regression model\n","def train_linear_regression(df):\n","    X = df[['M&A_Frequency', 'Yield_Curve_Inversion', 'Political_Party_Control', 'Data_Readouts', 'M&A_Size']]\n","    y = df['XBI_Returns']\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    return model, y_pred\n","\n","# Train linear regression model for Mega M&A\n","model, y_pred = train_linear_regression(df_mega_ma)\n","\n","# Function to evaluate model performance\n","def evaluate_model_performance(model, y_pred):\n","    mse = mean_squared_error(y_test, y_pred)\n","    return mse\n","\n","# Evaluate model performance for Mega M&A\n","mse = evaluate_model_performance(model, y_pred)\n","\n","print(f'Mean Squared Error: {mse}')\n","\n","# Function to generate predictions\n","def generate_predictions(model, X_new):\n","    predictions = model.predict(X_new)\n","    return predictions\n","\n","# Generate predictions for Mega M&A\n","X_new = df_mega_ma[['M&A_Frequency', 'Yield_Curve_Inversion', 'Political_Party_Control', 'Data_Readouts', 'M&A_Size']]\n","predictions = generate_predictions(model, X_new)\n","\n","print(f'Predictions: {predictions}')\n","\n","# Function to create scatter plot\n","def create_scatter_plot(df):\n","    plt.figure(figsize=(10,6))\n","    sns.scatterplot(x='M&A_Frequency', y='XBI_Returns', data=df)\n","    plt.title('M&A Frequency vs XBI Returns')\n","    plt.xlabel('M&A Frequency')\n","    plt.ylabel('XBI Returns')\n","    plt.show()\n","\n","# Create scatter plot for Mega M&A\n","create_scatter_plot(df_mega_ma)\n","\n","# Function to create bar chart\n","def create_bar_chart(df):\n","    plt.figure(figsize=(10,6))\n","    sns.barplot(x='M&A_Size', y='XBI_Returns', data=df)\n","    plt.title('M&A Size vs XBI Returns')\n","    plt.xlabel('M&A Size')\n","    plt.ylabel('XBI Returns')\n","    plt.show()\n","\n","# Create bar chart for Mega M&A\n","create_bar_chart(df_mega_ma)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"pM0RxnYwRnx4","executionInfo":{"status":"error","timestamp":1724903928273,"user_tz":420,"elapsed":282,"user":{"displayName":"Mukeshwaran Baskaran","userId":"01625547661572205085"}},"outputId":"cec83cf2-e3bc-4eaa-c915-d2a65ac894fd"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Year'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Year'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-ef35c020e301>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Calculate political party control for Mega M&A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdf_mega_ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_political_party_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_mega_ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Function to calculate data readouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-ef35c020e301>\u001b[0m in \u001b[0;36mcalculate_political_party_control\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Function to calculate political party control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_political_party_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Political_Party_Control'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Democratic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Republican'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Other'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m             ):\n\u001b[1;32m   3797\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Year'"]}]},{"cell_type":"code","source":["\n","# Step 1: Calculate Weekly Changes in XBI Market Cap\n","df_mktcap_xbi['Market_Cap_Change'] = df_mktcap_xbi['CUR_MKT_CAP'].diff()\n","\n","\n","# Step 4: Calculate Yield Curve\n","df_us2y['Yield'] = df_us10y['PX_LAST'] - df_us2y['PX_LAST']\n","\n"],"metadata":{"id":"BuCNqECW2OBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 11: Investigate Impact of Yield Curve Inversion\n","df_xbi['Yield_Curve_Inverted'] = df_us2y['PX_LAST'] < df_us10y['PX_LAST']\n","yield_curve_inversion = df_xbi.groupby('Yield_Curve_Inverted')['Weekly_Return'].mean()\n","\n","print(\"Average XBI weekly return during yield curve inversion:\\n\", yield_curve_inversion)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"DF2hP2cO2Xyb","executionInfo":{"status":"error","timestamp":1724896739925,"user_tz":420,"elapsed":249,"user":{"displayName":"Mukeshwaran Baskaran","userId":"01625547661572205085"}},"outputId":"be13df1f-5dea-4c2f-dc8b-c04ff20b3ea3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Column not found: Weekly_Return'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-dcdb55eed0b1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 11: Investigate Impact of Yield Curve Inversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_xbi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Yield_Curve_Inverted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_us2y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PX_LAST'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mdf_us10y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PX_LAST'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0myield_curve_inversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_xbi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Yield_Curve_Inverted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Weekly_Return'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average XBI weekly return during yield curve inversion:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myield_curve_inversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m                 \u001b[0;34m\"Use a list instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m             )\n\u001b[0;32m-> 1964\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column not found: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Column not found: Weekly_Return'"]}]}],"metadata":{"kernelspec":{"display_name":"HW2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}